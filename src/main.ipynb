{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac29148",
   "metadata": {},
   "source": [
    "# Named Entity Recognition\n",
    "Theoretical explanation is present in this blogpost [link](). The project aims to use Bidirectional-LSTM with Conditional Random Fields along with static word embeddings to perform Named Entity Recognition task based off of the CoNLL-2003 dataset. This will be done step by step from downloading and preparing the dataset, embeddings, to training and validating the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca92aec",
   "metadata": {},
   "source": [
    "## 1. Dataset downloading and preprocessing\n",
    "The first step is to download both the dataset which contains the tagged information as well as the static embeddings GloVe, which has vectors with embedded meanings for words. Since BiLSTM cannot generated contextualised vectors like BERT and other transformer models do (a natural improvement), we fallback to using GloVe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f3a2b",
   "metadata": {},
   "source": [
    "### 1.1 Downloading GloVe Embeddings\n",
    "We will download the 100 dimensional variant of GloVe (there's a 300 dimensional variant which is heavy but more accurate). This is available for your exploration at [Stanford NLP Github](https://github.com/stanfordnlp/GloVe/releases). The following script uses utility function to download this automatically and unzips to `src/data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5a4233",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.download import download_glove_embeddings, download_conll2003_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8691d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe embeddings already exist. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "download_glove_embeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e523a0c0",
   "metadata": {},
   "source": [
    "### 1.2 Downloading the CoNLL2003 Dataset\n",
    "The following method downloads the CoNLL2003 NER dataset in the same location as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d8db71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoNLL-2003 dataset already exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "download_conll2003_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe81693e",
   "metadata": {},
   "source": [
    "### 1.3 Loading the GloVe embeddings, CoNLL Data and create the dataset loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7e9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.data import load_glove_embeddings, load_conll_dataset\n",
    "from util.dataset import create_data_loader\n",
    "from util.adapters import bio_tag_dictionary\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61133e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embeddings from file.\n",
      "Loaded 400002 words into vocabulary from GloVe.\n",
      "Loading CoNLL data from data/conll2003/train.txt\n",
      "Dataset loaded.\n",
      "Loading CoNLL data from data/conll2003/test.txt\n",
      "Dataset loaded.\n",
      "Loading CoNLL data from data/conll2003/valid.txt\n",
      "Dataset loaded.\n"
     ]
    }
   ],
   "source": [
    "# Load the GloVe embeddings\n",
    "word2idx, embeddings, dimensions = load_glove_embeddings()\n",
    "\n",
    "# Load the CoNLL as data\n",
    "train_data, test_data, val_data = load_conll_dataset()\n",
    "# Use the Train data as sample to get the tag dictionary\n",
    "tag2label, label2tag = bio_tag_dictionary(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4f2f7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dimensions == 100\n",
    "assert word2idx[\"the\"] == 2\n",
    "np.testing.assert_allclose(\n",
    "    embeddings[word2idx[\"the\"]],\n",
    "    np.array([-0.038194, -0.24487, 0.72812, -0.39961, 0.083172, 0.043953, -0.39141, 0.3344, -0.57545, 0.087459, 0.28787, -0.06731, 0.30906, -0.26384, -0.13231, -0.20757, 0.33395, -0.33848, -0.31743, -0.48336, 0.1464, -0.37304, 0.34577, 0.052041, 0.44946, -0.46971, 0.02628, -0.54155, -0.15518, -0.14107, -0.039722, 0.28277, 0.14393, 0.23464, -0.31021, 0.086173, 0.20397, 0.52624, 0.17164, -0.082378, -0.71787, -0.41531, 0.20335, -0.12763, 0.41367, 0.55187, 0.57908, -0.33477,\n",
    "              -0.36559, -0.54857, -0.062892, 0.26584, 0.30205, 0.99775, -0.80481, -3.0243, 0.01254, -0.36942, 2.2167, 0.72201, -0.24978, 0.92136, 0.034514, 0.46745, 1.1079, -0.19358, -0.074575, 0.23353, -0.052062, -0.22044, 0.057162, -0.15806, -0.30798, -0.41625, 0.37972, 0.15006, -0.53212, -0.2055, -1.2526, 0.071624, 0.70565, 0.49744, -0.42063, 0.26148, -1.538, -0.30223, -0.073438, -0.28312, 0.37104, -0.25217, 0.016215, -0.017099, -0.38984, 0.87424, -0.72569, -0.51058, -0.52028, -0.1459, 0.8278, 0.27062]),\n",
    "    rtol=1e-5,\n",
    "    atol=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d4efa6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['eu', 'rejects', 'german', 'call', 'to', 'boycott', 'british', 'lamb', '.'],\n",
       " ['b-org', 'o', 'b-misc', 'o', 'o', 'o', 'b-misc', 'o', 'o']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=16\n",
    "NUM_WORKERS=0\n",
    "\n",
    "# Create the actual dataloader\n",
    "train_data_loader = create_data_loader(\n",
    "    train_data, word2idx, tag2label, embeddings, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "val_data_loader = create_data_loader(\n",
    "    val_data, word2idx, tag2label, embeddings, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, \n",
    "    is_train=False)\n",
    "test_data_loader = create_data_loader(\n",
    "    test_data, word2idx, tag2label, embeddings, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, \n",
    "    is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4bf032",
   "metadata": {},
   "source": [
    "## 2. Creating the Runner Instance and run training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cc1c770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from runner import Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29f402ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constants here\n",
    "LEARNING_RATE = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e9f16e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(LEARNING_RATE, train_data_loader, val_data_loader,\n",
    "                test_data_loader, dimensions, len(tag2label.keys()), 30, None, label2tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f76c60",
   "metadata": {},
   "source": [
    "### 2.1. Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6ae1cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4b415499484dd8b0e37038a9e4e499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training progress:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30, Training loss: 494.40, Validation loss: 408.99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x11a67ea20>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sriharikarthickn/Developer/Tools/miniconda3/envs/project/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1663, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/sriharikarthickn/Developer/Tools/miniconda3/envs/project/lib/python3.13/site-packages/torch/utils/data/dataloader.py\", line 1627, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/sriharikarthickn/Developer/Tools/miniconda3/envs/project/lib/python3.13/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/sriharikarthickn/Developer/Tools/miniconda3/envs/project/lib/python3.13/multiprocessing/popen_fork.py\", line 41, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/sriharikarthickn/Developer/Tools/miniconda3/envs/project/lib/python3.13/multiprocessing/connection.py\", line 1148, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/sriharikarthickn/Developer/Tools/miniconda3/envs/project/lib/python3.13/selectors.py\", line 398, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "  File \"/Users/sriharikarthickn/Developer/Tools/miniconda3/envs/project/lib/python3.13/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 3666) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Projects/Python/NLP/named-entity-recognition/src/runner.py:37\u001b[39m, in \u001b[36mRunner.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tokens, tags, masks \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.train_loader:\n\u001b[32m     36\u001b[39m     \u001b[38;5;28mself\u001b[39m.optimiser.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     loss = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     train_loss += loss.item()\n\u001b[32m     39\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Tools/miniconda3/envs/project/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Tools/miniconda3/envs/project/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Projects/Python/NLP/named-entity-recognition/src/model/bilstm.py:32\u001b[39m, in \u001b[36mBiLSTMNER.forward\u001b[39m\u001b[34m(self, x, tags, mask)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor, tags: torch.LongTensor = \u001b[38;5;28;01mNone\u001b[39;00m, mask: torch.BoolTensor = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     21\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"The forward propagation step of the network. Goes through a bidirectional lstm network, followed by a\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m    dense network and then finally passing through the CRF layer to prevent malformed tags.\u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33;03m        _type_: _description_\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     emissions, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblstml1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m     emissions = \u001b[38;5;28mself\u001b[39m.dense1(emissions)\n\u001b[32m     35\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     36\u001b[39m         \u001b[38;5;66;03m# negative log likelihood loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Tools/miniconda3/envs/project/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Tools/miniconda3/envs/project/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Developer/Tools/miniconda3/envs/project/lib/python3.13/site-packages/torch/nn/modules/rnn.py:1124\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1121\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1124\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1125\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1126\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1127\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1136\u001b[39m     result = _VF.lstm(\n\u001b[32m   1137\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1138\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1145\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1146\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "runner.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2436ebd8",
   "metadata": {},
   "source": [
    "### 2.2. Testing with test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9a7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"ENTER PATH TO FILE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a63745",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = Runner(LEARNING_RATE, train_data_loader, val_data_loader,\n",
    "                test_data_loader, dimensions, len(tag2label.keys()), 30, filename, label2tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e48f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
